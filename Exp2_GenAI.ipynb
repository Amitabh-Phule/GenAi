{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBVzT2motQdZbEhkdtXX7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amitabh-Phule/GenAi/blob/main/Exp2_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objectives:**\n",
        "\n",
        "1. To study advanced prompting techniques in Large Language Models (LLMs).\n",
        "\n",
        "2. To implement Chain-of-Thought prompting for reasoning-based tasks.\n",
        "\n",
        "3. To implement Few-Shot learning for classification problems."
      ],
      "metadata": {
        "id": "mobRSqztGW3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Required Library**"
      ],
      "metadata": {
        "id": "gzH1F6KNEGCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet OpenAI"
      ],
      "metadata": {
        "id": "VImsPCk_7RlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Environment Setup and API Configuration**"
      ],
      "metadata": {
        "id": "TJoD3Sg_Egx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_GNz8LYTG3tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"PASTE_YOUR_OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "Q1EQBEHe7lde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load API Key**"
      ],
      "metadata": {
        "id": "SXkFf6HiEtIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "assert api_key is not None,\"API key not found!\"\n",
        "print(\"API KEY Loaded Successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ry6fSB7zQU",
        "outputId": "ff07a66f-8642-4dd1-c342-5d23120b57b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API KEY Loaded Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI Client Initialization and Utility Function**"
      ],
      "metadata": {
        "id": "dOntBeFrE-J8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OpenAI Client and Helper Function**"
      ],
      "metadata": {
        "id": "XZQfNDSeFC-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "def call_openai(prompt, temperature=0.2):\n",
        "    \"\"\"\n",
        "    Sends a prompt to the OpenAI chat model and returns the generated response.\n",
        "\n",
        "    Parameters:\n",
        "        prompt (str): Input prompt\n",
        "        temperature (float): Controls randomness of the response\n",
        "\n",
        "    Returns:\n",
        "        str: Model-generated output\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Rt5f_mGJ8j-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step-by-Step Reasoning Prompt (Chain-of-Thought Style)**"
      ],
      "metadata": {
        "id": "fLT3LbXmFUeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step-by-Step Prompt Function**"
      ],
      "metadata": {
        "id": "LLvl81g4FX8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def step_by_step_solution(question):\n",
        "    \"\"\"\n",
        "    Generates a structured step-by-step explanation for a given problem.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Solve the problem step by step and give a clear explanation.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    return call_openai(prompt, temperature=0.2)\n"
      ],
      "metadata": {
        "id": "WO4WOScn-7yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Step-by-Step Prompt**"
      ],
      "metadata": {
        "id": "18gJjbkcFrmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_of_thought(\n",
        "    'A cyclist rides 90 km in 3 hours. What is the average speed?'\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7RcsJXCH-99N",
        "outputId": "b72adeca-5344-4d19-ef94-9139d59dfa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the average speed of the cyclist, we can follow these steps:\n",
            "\n",
            "### Step 1: Understand the formula for average speed\n",
            "The average speed is calculated using the formula:\n",
            "\n",
            "\\[\n",
            "\\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}}\n",
            "\\]\n",
            "\n",
            "### Step 2: Identify the total distance and total time\n",
            "From the problem, we know:\n",
            "- Total Distance = 90 km\n",
            "- Total Time = 3 hours\n",
            "\n",
            "### Step 3: Substitute the values into the formula\n",
            "Now we can substitute the values into the average speed formula:\n",
            "\n",
            "\\[\n",
            "\\text{Average Speed} = \\frac{90 \\text{ km}}{3 \\text{ hours}}\n",
            "\\]\n",
            "\n",
            "### Step 4: Perform the division\n",
            "Now, we divide 90 km by 3 hours:\n",
            "\n",
            "\\[\n",
            "\\text{Average Speed} = 30 \\text{ km/h}\n",
            "\\]\n",
            "\n",
            "### Step 5: State the final answer\n",
            "The average speed of the cyclist is **30 km/h**.\n",
            "\n",
            "### Conclusion\n",
            "By following these steps, we have calculated the average speed of the cyclist based on the distance traveled and the time taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Few-Shot Prompting for Sentiment Classification**"
      ],
      "metadata": {
        "id": "5NOqida6FwNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Few-Shot Sentiment Function**"
      ],
      "metadata": {
        "id": "AqMOjiU_F7Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_sentiment(text):\n",
        "    \"\"\"\n",
        "    Classifies sentiment using few-shot prompting.\n",
        "\n",
        "    Output classes:\n",
        "    - Positive\n",
        "    - Negative\n",
        "    - Neutral\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Classify the sentiment as Positive, Negative, or Neutral.\n",
        "\n",
        "Example 1:\n",
        "Text: I love this movie.\n",
        "Sentiment: Positive\n",
        "\n",
        "Example 2:\n",
        "Text: This is the worst product I have ever bought.\n",
        "Sentiment: Negative\n",
        "\n",
        "Example 3:\n",
        "Text: The delivery arrived on time.\n",
        "Sentiment: Neutral\n",
        "\n",
        "Now classify:\n",
        "Text: {text}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "    return call_openai(prompt, temperature=0)\n"
      ],
      "metadata": {
        "id": "m9inBlAi_Hgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Few-Shot Prompt**"
      ],
      "metadata": {
        "id": "2D2GsHR-GEEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    few_shot_sentiment(\n",
        "        \"The food was ok but overpriced.\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-tQmX66_adW",
        "outputId": "b0ea9645-04ed-4c56-da89-03ce53e6a321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Neutral\n"
          ]
        }
      ]
    }
  ]
}